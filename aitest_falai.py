import argparse
import json
import time
from datetime import datetime

import fal
import fal_client
from fal.toolkit.image import Image
from pydantic import BaseModel, Field


class HelloWorldApp(fal.App):
    @fal.endpoint("/hello")
    def run(self) -> dict:
        return {"message": "Hello, World!"}


class ImageRequest(BaseModel):
    prompt: str = Field(description="Image generation prompt")
    num_inference_steps: int = Field(default=28, description="Number of inference steps")
    width: int = Field(default=1024, description="Image width")
    height: int = Field(default=1024, description="Image height")


class ImageResponse(BaseModel):
    image: Image


class StableDiffusionApp(fal.App):
    # GPU ì„ íƒ (ì˜ˆ: "GPU-H100", "GPU-A100", "GPU-L4")
    machine_type = "GPU-H100"

    requirements = [
        "diffusers==0.30.3",
        "torch==2.6.0",
        "transformers==4.47.1",
        "accelerate",
    ]

    async def setup(self) -> None:
        from diffusers import StableDiffusionPipeline
        import torch

        print("Loading model...")
        self.pipe = StableDiffusionPipeline.from_pretrained(
            "stabilityai/stable-diffusion-2-1",
            torch_dtype=torch.float16,
        ).to("cuda")
        print("Model loaded successfully!")

    @fal.endpoint("/")
    async def generate(self, request: ImageRequest) -> ImageResponse:
        print(f"Generating image with prompt: {request.prompt}")
        result = self.pipe(
            prompt=request.prompt,
            num_inference_steps=request.num_inference_steps,
            width=request.width,
            height=request.height,
        )
        image = result.images[0]
        return ImageResponse(image=Image.from_pil(image))


class GPUPerformanceTest:
    def __init__(self, app_url: str, gpu_name: str):
        self.app_url = app_url
        self.gpu_name = gpu_name
        self.results = []

    def run_test(self, num_tests: int = 10, prompt: str = "a cat wearing a hat") -> None:
        print(f"\n{'=' * 50}")
        print(f"í…ŒìŠ¤íŠ¸ ì‹œì‘: {self.gpu_name}")
        print(f"ì‹œê°„: {datetime.now()}")
        print(f"{'=' * 50}\n")

        for i in range(num_tests):
            print(f"í…ŒìŠ¤íŠ¸ {i + 1}/{num_tests}...")
            start_time = time.time()

            try:
                result = fal_client.submit(
                    self.app_url,
                    arguments={
                        "prompt": f"{prompt} {i}",
                        "num_inference_steps": 28,
                    },
                )
                output = result.get()
                elapsed_time = time.time() - start_time

                self.results.append(
                    {
                        "test_num": i + 1,
                        "time": elapsed_time,
                        "success": True,
                        "image_url": output.get("image", {}).get("url", ""),
                    }
                )
                print(f"  âœ“ ì™„ë£Œ: {elapsed_time:.2f}ì´ˆ")
            except Exception as exc:
                elapsed_time = time.time() - start_time
                self.results.append(
                    {
                        "test_num": i + 1,
                        "time": elapsed_time,
                        "success": False,
                        "error": str(exc),
                    }
                )
                print(f"  âœ— ì‹¤íŒ¨: {exc}")

        self.print_summary()
        self.save_results()

    def print_summary(self) -> None:
        successful_results = [r for r in self.results if r["success"]]

        if not successful_results:
            print("\nâš ï¸ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return

        times = [r["time"] for r in successful_results]
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        images_per_hour = 3600 / avg_time if avg_time > 0 else 0

        print(f"\n{'=' * 50}")
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½: {self.gpu_name}")
        print(f"{'=' * 50}")
        print(f"ì„±ê³µ: {len(successful_results)}/{len(self.results)}")
        print(f"í‰ê·  ìƒì„±ì‹œê°„: {avg_time:.2f}ì´ˆ")
        print(f"ìµœì†Œ ìƒì„±ì‹œê°„: {min_time:.2f}ì´ˆ")
        print(f"ìµœëŒ€ ìƒì„±ì‹œê°„: {max_time:.2f}ì´ˆ")
        print(f"ì‹œê°„ë‹¹ ìƒì„±ëŸ‰: {images_per_hour:.0f}ì¥")
        print(f"{'=' * 50}\n")

    def save_results(self) -> None:
        filename = f"test_results_{self.gpu_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, "w", encoding="utf-8") as file:
            json.dump(
                {
                    "gpu": self.gpu_name,
                    "test_count": len(self.results),
                    "results": self.results,
                },
                file,
                indent=2,
                ensure_ascii=False,
            )
        print(f"ê²°ê³¼ ì €ì¥: {filename}")


def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="fal.ai í…ŒìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹°")
    parser.add_argument(
        "--performance",
        action="store_true",
        help="GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰",
    )
    parser.add_argument(
        "--app-url",
        default="username/h100-app",
        help="ë°°í¬ëœ ì•± URL (ì˜ˆ: username/h100-app)",
    )
    parser.add_argument(
        "--gpu-name",
        default="H100",
        help="GPU ì´ë¦„ (ì˜ˆ: H100)",
    )
    parser.add_argument(
        "--num-tests",
        type=int,
        default=10,
        help="í…ŒìŠ¤íŠ¸ íšŸìˆ˜",
    )
    parser.add_argument(
        "--prompt",
        default="a cat wearing a hat",
        help="ê¸°ë³¸ í”„ë¡¬í”„íŠ¸",
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = _parse_args()
    if args.performance:
        print("âš ï¸ í…ŒìŠ¤íŠ¸ ì „ì— https://fal.ai/dashboard/billing ì—ì„œ í¬ë ˆë”§ì„ ê¸°ë¡í•˜ì„¸ìš”!")
        input("ì¤€ë¹„ë˜ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        tester = GPUPerformanceTest(args.app_url, args.gpu_name)
        tester.run_test(num_tests=args.num_tests, prompt=args.prompt)
